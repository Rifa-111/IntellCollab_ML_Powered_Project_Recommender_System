{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pymongo import MongoClient\n",
    "from flask import Flask, render_template, request\n",
    "\n",
    "# Initialize Flask\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient('mongodb+srv://w1798587:Success%402024@cluster0.69rs1dl.mongodb.net/')\n",
    "db = client['MyDatabase']\n",
    "collection = db['Faculty_Project']\n",
    "\n",
    "# Retrieve data from MongoDB\n",
    "cursor = collection.find()\n",
    "\n",
    "# Convert data to DataFrame\n",
    "data = list(cursor)\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from MongoDB into DataFrame\n",
    "def load_data():\n",
    "    cursor = collection.find()\n",
    "    data = list(cursor)\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "# Convert data to DataFrame\n",
    "data = list(cursor)\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to DataFrame\n",
    "data = list(cursor)\n",
    "df = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "def preprocess_data(df):\n",
    "    # Remove duplicates\n",
    "    df.drop_duplicates(subset=['Industry_Project_Name'], keep='first', inplace=True)\n",
    "    # Remove rows with missing values\n",
    "    df.dropna(subset=['Project_Description', 'Skills', 'Industry_Company_Name'], inplace=True)\n",
    "    # Standardize text data\n",
    "    df['Project_Description'] = df['Project_Description'].str.lower().str.replace('[^\\w\\s]', '')\n",
    "    df['Skills'] = df['Skills'].str.lower().str.replace('[^\\w\\s]', '')\n",
    "    df['Industry_Company_Name'] = df['Industry_Company_Name'].str.lower().str.replace('[^\\w\\s]', '')\n",
    "    # Extract length of project descriptions as a feature\n",
    "    df['Description_Length'] = df['Project_Description'].apply(len)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the logistic regression model\n",
    "def train_model(X_train_tfidf, y_train):\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "df = load_data()\n",
    "df = preprocess_data(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into features (X) and target variable (y)\n",
    "X = df[['Project_Description', 'Skills']]\n",
    "y = df['Industry_Project_Name']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Content-Based Filtering\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train['Project_Description'] + ' ' + X_train['Skills'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_tfidf, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "np.nan is an invalid document, expected byte or unicode string.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 29\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Content-Based Filtering\u001b[39;00m\n\u001b[1;32m     28\u001b[0m tfidf_vectorizer \u001b[38;5;241m=\u001b[39m TfidfVectorizer(stop_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 29\u001b[0m tfidf_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mtfidf_vectorizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSkills\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Define evaluation function\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_recommendation_system\u001b[39m(ground_truth, predicted_values):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:2139\u001b[0m, in \u001b[0;36mTfidfVectorizer.fit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   2132\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params()\n\u001b[1;32m   2133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf \u001b[38;5;241m=\u001b[39m TfidfTransformer(\n\u001b[1;32m   2134\u001b[0m     norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm,\n\u001b[1;32m   2135\u001b[0m     use_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_idf,\n\u001b[1;32m   2136\u001b[0m     smooth_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msmooth_idf,\n\u001b[1;32m   2137\u001b[0m     sublinear_tf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msublinear_tf,\n\u001b[1;32m   2138\u001b[0m )\n\u001b[0;32m-> 2139\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2140\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[1;32m   2141\u001b[0m \u001b[38;5;66;03m# X is already a transformed view of raw_documents so\u001b[39;00m\n\u001b[1;32m   2142\u001b[0m \u001b[38;5;66;03m# we set copy to False\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:1389\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1381\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1382\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1383\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1384\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1385\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1386\u001b[0m             )\n\u001b[1;32m   1387\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 1389\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_vocabulary_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[1;32m   1392\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:1276\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1274\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m raw_documents:\n\u001b[1;32m   1275\u001b[0m     feature_counter \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m-> 1276\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m \u001b[43manalyze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1277\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1278\u001b[0m             feature_idx \u001b[38;5;241m=\u001b[39m vocabulary[feature]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:105\u001b[0m, in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Chain together an optional series of text processing steps to go from\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03ma single document to ngrams, with or without tokenizing or preprocessing.\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m    A sequence of tokens, possibly with pairs, triples, etc.\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m decoder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 105\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m analyzer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    107\u001b[0m     doc \u001b[38;5;241m=\u001b[39m analyzer(doc)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:238\u001b[0m, in \u001b[0;36m_VectorizerMixin.decode\u001b[0;34m(self, doc)\u001b[0m\n\u001b[1;32m    235\u001b[0m     doc \u001b[38;5;241m=\u001b[39m doc\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecode_error)\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m doc \u001b[38;5;129;01mis\u001b[39;00m np\u001b[38;5;241m.\u001b[39mnan:\n\u001b[0;32m--> 238\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    239\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnp.nan is an invalid document, expected byte or unicode string.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    240\u001b[0m     )\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m doc\n",
      "\u001b[0;31mValueError\u001b[0m: np.nan is an invalid document, expected byte or unicode string."
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, request, redirect, url_for\n",
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# MongoDB connection\n",
    "client = MongoClient(\"mongodb://localhost:27017/\")\n",
    "db = client[\"IntellCollab\"]\n",
    "collection = db['User_Project']\n",
    "\n",
    "# Load data from MongoDB\n",
    "cursor = collection.find()\n",
    "data = list(cursor)\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Remove duplicates and missing values, preprocess text data, and extract features\n",
    "# (your existing preprocessing code goes here)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Content-Based Filtering\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df['Skills'])\n",
    "\n",
    "# Define evaluation function\n",
    "def evaluate_recommendation_system(ground_truth, predicted_values):\n",
    "    accuracy = accuracy_score(ground_truth, predicted_values)\n",
    "    precision = precision_score(ground_truth, predicted_values)\n",
    "    recall = recall_score(ground_truth, predicted_values)\n",
    "    f1 = f1_score(ground_truth, predicted_values)\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# Ground truth and predicted values\n",
    "# Example: ground_truth = [1, 0, 1, 1, 0]  # Example ground truth values (1: relevant, 0: not relevant)\n",
    "# Example: predicted_values = [1, 1, 0, 1, 0]  # Example predicted values\n",
    "\n",
    "# Define route for recommendation\n",
    "@app.route('/recommend_projects', methods=['POST'])\n",
    "def recommend_projects():\n",
    "    # Get user input\n",
    "    skills = request.form.get('skills')\n",
    "    if skills:\n",
    "        # Perform recommendation (your existing recommendation code goes here)\n",
    "        \n",
    "        # For evaluation purposes, let's assume you have ground truth and predicted values\n",
    "        ground_truth = [1, 0, 1, 1, 0]  # Example ground truth values (1: relevant, 0: not relevant)\n",
    "        predicted_values = [1, 1, 0, 1, 0]  # Example predicted values\n",
    "        \n",
    "        # Evaluate recommendation system\n",
    "        accuracy, precision, recall, f1 = evaluate_recommendation_system(ground_truth, predicted_values)\n",
    "        \n",
    "        # Print evaluation scores\n",
    "        print(\"Accuracy:\", accuracy)\n",
    "        print(\"Precision:\", precision)\n",
    "        print(\"Recall:\", recall)\n",
    "        print(\"F1 Score:\", f1)\n",
    "        \n",
    "        # Pass evaluation metrics to template\n",
    "        return render_template('dashboard.html', accuracy=accuracy, precision=precision, recall=recall, f1=f1)\n",
    "    else:\n",
    "        # If no skills provided, return empty recommendations\n",
    "        recommended_projects = []\n",
    "        return render_template('dashboard.html', recommended_projects=recommended_projects)\n",
    "\n",
    "# Other routes and functions...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_rf_classifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 31\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Initialize Random Forest Classifier\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \n\u001b[1;32m     26\u001b[0m \n\u001b[1;32m     27\u001b[0m \n\u001b[1;32m     28\u001b[0m \n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Predict on test data\u001b[39;00m\n\u001b[1;32m     30\u001b[0m X_test_tfidf \u001b[38;5;241m=\u001b[39m tfidf_vectorizer\u001b[38;5;241m.\u001b[39mtransform(X_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSkills\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 31\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mbest_rf_classifier\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(X_test_tfidf)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Calculate accuracy\u001b[39;00m\n\u001b[1;32m     34\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_pred)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_rf_classifier' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient('mongodb+srv://w1798587:Success%402024@cluster0.69rs1dl.mongodb.net/')\n",
    "db = client['IntellCollab']\n",
    "collection = db['User_Project']\n",
    "\n",
    "# Split data into features (X) and target variable (y)\n",
    "X = df[['Skills']]\n",
    "y = df['Industry_Project_Name']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train['Skills'])\n",
    "\n",
    "# Initialize Random Forest Classifier\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Predict on test data\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test['Skills'])\n",
    "y_pred = best_rf_classifier.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'develop solar-powered solutions for efficient water pumping systems'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/58/vdk28sms6qxgzmkckgchtb_h0000gn/T/ipykernel_4377/3540994841.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Standardize the input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mX_train_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mX_test_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Define the neural network model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             return_tuple = (\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    912\u001b[0m         \u001b[0;31m# non-optimized default implementation; override when a better\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m         \u001b[0;31m# method is possible for a given clustering algorithm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    835\u001b[0m             \u001b[0mFitted\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m         \"\"\"\n\u001b[1;32m    837\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 839\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1148\u001b[0m                 skip_parameter_validation=(\n\u001b[1;32m   1149\u001b[0m                     \u001b[0mprefer_skip_nested_validation\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m                 )\n\u001b[1;32m   1151\u001b[0m             ):\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0mFitted\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m         \"\"\"\n\u001b[1;32m    874\u001b[0m         \u001b[0mfirst_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"n_samples_seen_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 875\u001b[0;31m         X = self._validate_data(\n\u001b[0m\u001b[1;32m    876\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    601\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    912\u001b[0m                         )\n\u001b[1;32m    913\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m                 raise ValueError(\n\u001b[1;32m    918\u001b[0m                     \u001b[0;34m\"Complex data not supported\\n{}\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m                 ) from complex_warning\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0;31m# Use NumPy API to support order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;31m# container that is consistent with the input's namespace.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   2148\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2150\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2151\u001b[0m         if (\n\u001b[1;32m   2152\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2153\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'develop solar-powered solutions for efficient water pumping systems'"
     ]
    }
   ],
   "source": [
    "from altair import SequentialMultiHue\n",
    "from networkx import dense_gnm_random_graph\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardize the input data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the neural network model\n",
    "model = SequentialMultiHue()\n",
    "model.add(dense_gnm_random_graph(100, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model on your data\n",
    "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=64, validation_data=(X_test_scaled, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(\"Test Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['Description_Length'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[139], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Select numeric features for scaling\u001b[39;00m\n\u001b[1;32m      4\u001b[0m numeric_features \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDescription_Length\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Assuming 'Description_Length' is numeric\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m X_train_numeric \u001b[38;5;241m=\u001b[39m \u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnumeric_features\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      6\u001b[0m X_test_numeric \u001b[38;5;241m=\u001b[39m X_test[numeric_features]\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Standardize the numeric features\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/frame.py:4096\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4094\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4095\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4096\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4098\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexes/base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[1;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[0;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['Description_Length'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Select numeric features for scaling\n",
    "numeric_features = ['Description_Length']  # Assuming 'Description_Length' is numeric\n",
    "X_train_numeric = X_train[numeric_features]\n",
    "X_test_numeric = X_test[numeric_features]\n",
    "\n",
    "# Standardize the numeric features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled_numeric = scaler.fit_transform(X_train_numeric)\n",
    "X_test_scaled_numeric = scaler.transform(X_test_numeric)\n",
    "\n",
    "\n",
    "\n",
    "# Replace the original numeric features with scaled ones\n",
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "X_train_scaled[numeric_features] = X_train_scaled_numeric\n",
    "X_test_scaled[numeric_features] = X_test_scaled_numeric\n",
    "\n",
    "# Now you can use X_train_scaled and X_test_scaled for prediction and evaluation\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Compute evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='micro')\n",
    "recall = recall_score(y_test, y_pred, average='micro')\n",
    "f1 = f1_score(y_test, y_pred, average='micro')\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "''' import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Simulate predictions for demonstration purpose\n",
    "y_pred = model.predict(X_train_tfidf)\n",
    "\n",
    "# Compute evaluation metrics\n",
    "precision = precision_score(y_train, y_pred, average='micro')\n",
    "recall = recall_score(y_train, y_pred, average='micro')\n",
    "f1 = f1_score(y_train, y_pred, average='micro')\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "# Print evaluation metrics\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Plot evaluation metrics\n",
    "metrics = ['Precision', 'Recall', 'F1 Score', 'Accuracy']\n",
    "scores = [precision, recall, f1, accuracy]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(metrics, scores, color=['blue', 'green', 'orange', 'red'])\n",
    "plt.xlabel('Metrics')\n",
    "plt.ylabel('Scores')\n",
    "plt.title('Evaluation Metrics')\n",
    "plt.show()\n",
    " '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_test_tfidf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m precision_score, recall_score, f1_score\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Predict the target variable for the test set\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(\u001b[43mX_test_tfidf\u001b[49m)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Calculate precision, recall, and F1 score\u001b[39;00m\n\u001b[1;32m     30\u001b[0m precision \u001b[38;5;241m=\u001b[39m precision_score(y_test, y_pred, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmicro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_test_tfidf' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Predict probabilities for the test set\n",
    "y_pred_proba = model.predict_proba(X_train_tfidf)\n",
    "\n",
    "# Extract probabilities for the positive class\n",
    "positive_class_index = 1  # Assuming the positive class is at index 1\n",
    "y_pred_proba_positive = y_pred_proba[:, positive_class_index]\n",
    "\n",
    "# Sort the probabilities for plotting\n",
    "y_pred_proba_positive_sorted = sorted(y_pred_proba_positive)\n",
    "\n",
    "# Create a line plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(y_pred_proba_positive_sorted, range(len(y_pred_proba_positive_sorted)), color='blue')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Predicted Probability (Positive Class)')\n",
    "plt.title('Line Plot of Predicted Probabilities for Positive Class')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Predict the target variable for the test set\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "precision = precision_score(y_test, y_pred, average='micro')\n",
    "recall = recall_score(y_test, y_pred, average='micro')\n",
    "f1 = f1_score(y_test, y_pred, average='micro')\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Make recommendations\n",
    "def recommend_projects(skills):\n",
    "    skills_vector = tfidf_vectorizer.transform([skills])\n",
    "    similarity_scores = model.predict_proba(skills_vector)[:, 1]  # Predict probabilities of relevance\n",
    "    recommendations = [(project, company, score) for project, company, score in zip(df['Industry_Project_Name'], df['Industry_Company_Name'], similarity_scores)]\n",
    "    recommendations.sort(key=lambda x: x[2], reverse=True)\n",
    "    return recommendations[:5]\n",
    "\n",
    "# Evaluate the recommendation system\n",
    "sample_test_data = X_test.sample(n=100, random_state=42)\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for description in sample_test_data:\n",
    "    skills = description  # Simulating user input as project description\n",
    "    project_skills = [skill.strip() for skill in skills.split(',')]\n",
    "    skills_vector = tfidf_vectorizer.transform([', '.join(project_skills)])\n",
    "    similarity_scores = model.predict_proba(skills_vector)[:, 1]  # Predict probabilities of relevance\n",
    "    recommended_projects = [(project, score) for project, score in zip(df['Industry_Project_Name'], similarity_scores)]\n",
    "    recommended_projects.sort(key=lambda x: x[1], reverse=True)\n",
    "    recommended_projects = recommended_projects[:5]  # Get top 5 recommended projects\n",
    "\n",
    "    # Assuming the relevance label is not available, we will treat all recommendations as relevant\n",
    "    relevant_projects = [project for project, _ in recommended_projects]\n",
    "\n",
    "    # Add ground truth and predictions for evaluation\n",
    "    y_true.append(relevant_projects)\n",
    "    y_pred.append(recommended_projects)\n",
    "\n",
    "# Flatten the lists for computing evaluation metrics\n",
    "y_true_flat = [project for sublist in y_true for project in sublist]\n",
    "y_pred_flat = [project for sublist in y_pred for project in sublist]\n",
    "\n",
    "# Compute evaluation metrics\n",
    "precision = precision_score(y_true_flat, y_pred_flat, average='micro')\n",
    "recall = recall_score(y_true_flat, y_pred_flat, average='micro')\n",
    "f1 = f1_score(y_true_flat, y_pred_flat, average='micro')\n",
    "# Visualize the evaluation metrics\n",
    "labels = ['Precision', 'Recall', 'F1 Score']\n",
    "values = [precision, recall, f1]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(labels, values, color=['blue', 'green', 'orange'])\n",
    "plt.title('Evaluation Metrics')\n",
    "plt.xlabel('Metric')\n",
    "plt.ylabel('Score')\n",
    "plt.ylim(0, 1)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'investigate cold war propaganda in american culture, analyzing films, television, and advertising as tools of ideological warfare during the cold war.'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/58/vdk28sms6qxgzmkckgchtb_h0000gn/T/ipykernel_7253/1015149256.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;31m# Standardize the input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m \u001b[0mX_train_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0mX_test_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;31m# Define the neural network model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             return_tuple = (\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    912\u001b[0m         \u001b[0;31m# non-optimized default implementation; override when a better\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m         \u001b[0;31m# method is possible for a given clustering algorithm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    835\u001b[0m             \u001b[0mFitted\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m         \"\"\"\n\u001b[1;32m    837\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 839\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1148\u001b[0m                 skip_parameter_validation=(\n\u001b[1;32m   1149\u001b[0m                     \u001b[0mprefer_skip_nested_validation\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m                 )\n\u001b[1;32m   1151\u001b[0m             ):\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0mFitted\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m         \"\"\"\n\u001b[1;32m    874\u001b[0m         \u001b[0mfirst_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"n_samples_seen_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 875\u001b[0;31m         X = self._validate_data(\n\u001b[0m\u001b[1;32m    876\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    601\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    912\u001b[0m                         )\n\u001b[1;32m    913\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m                 raise ValueError(\n\u001b[1;32m    918\u001b[0m                     \u001b[0;34m\"Complex data not supported\\n{}\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m                 ) from complex_warning\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0;31m# Use NumPy API to support order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;31m# container that is consistent with the input's namespace.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   2148\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2150\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2151\u001b[0m         if (\n\u001b[1;32m   2152\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2153\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'investigate cold war propaganda in american culture, analyzing films, television, and advertising as tools of ideological warfare during the cold war.'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pymongo import MongoClient\n",
    "from flask import Flask, render_template, request\n",
    "\n",
    "# Initialize Flask\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient('mongodb://localhost:27017/')\n",
    "db = client['IntellCollab']\n",
    "collection = db['User_Project']\n",
    "\n",
    "\n",
    "# Load data from MongoDB into DataFrame\n",
    "def load_data():\n",
    "    cursor = collection.find()\n",
    "    data = list(cursor)\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "# Preprocess the data\n",
    "def preprocess_data(df):\n",
    "    # Remove duplicates\n",
    "    df.drop_duplicates(subset=['Industry_Project_Name'], keep='first', inplace=True)\n",
    "    # Remove rows with missing values\n",
    "    df.dropna(subset=['Project_Description', 'Skills', 'Industry_Company_Name'], inplace=True)\n",
    "    # Standardize text data\n",
    "    df['Project_Description'] = df['Project_Description'].str.lower().str.replace('[^\\w\\s]', '')\n",
    "    df['Skills'] = df['Skills'].str.lower().str.replace('[^\\w\\s]', '')\n",
    "    df['Industry_Company_Name'] = df['Industry_Company_Name'].str.lower().str.replace('[^\\w\\s]', '')\n",
    "    # Extract length of project descriptions as a feature\n",
    "    df['Description_Length'] = df['Project_Description'].apply(len)\n",
    "    return df\n",
    "\n",
    "# Train the logistic regression model\n",
    "def train_model(X_train_tfidf, y_train):\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "    return model\n",
    "\n",
    "\n",
    "# Load and preprocess data\n",
    "df = load_data()\n",
    "df = preprocess_data(df)\n",
    "\n",
    "\n",
    "# Split data into features (X) and target variable (y)\n",
    "X = df[['Project_Description', 'Skills']]\n",
    "y = df['Industry_Project_Name']\n",
    "\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Content-Based Filtering\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train['Project_Description'] + ' ' + X_train['Skills'])\n",
    "\n",
    "# Train logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "from altair import SequentialMultiHue\n",
    "from networkx import dense_gnm_random_graph\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardize the input data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the neural network model\n",
    "model = SequentialMultiHue()\n",
    "model.add(dense_gnm_random_graph(100, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model on your data\n",
    "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=64, validation_data=(X_test_scaled, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Simulate predictions for demonstration purpose\n",
    "y_pred = model.predict(X_train_tfidf)\n",
    "\n",
    "# Compute evaluation metrics\n",
    "precision = precision_score(y_train, y_pred, average='micro')\n",
    "recall = recall_score(y_train, y_pred, average='micro')\n",
    "f1 = f1_score(y_train, y_pred, average='micro')\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "# Print evaluation metrics\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Plot evaluation metrics\n",
    "metrics = ['Precision', 'Recall', 'F1 Score', 'Accuracy']\n",
    "scores = [precision, recall, f1, accuracy]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(metrics, scores, color=['blue', 'green', 'orange', 'red'])\n",
    "plt.xlabel('Metrics')\n",
    "plt.ylabel('Scores')\n",
    "plt.title('Evaluation Metrics')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/rifa/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/rifa/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "/var/folders/58/vdk28sms6qxgzmkckgchtb_h0000gn/T/ipykernel_7548/3037243897.py:24: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.fillna('', inplace=True)\n",
      "/var/folders/58/vdk28sms6qxgzmkckgchtb_h0000gn/T/ipykernel_7548/3037243897.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['Skills'] = X['Skills'].str.split(',').apply(lambda x: ' '.join(x))  # Convert skills to separate features\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Mean Accuracy: 0.41339595845524696\n",
      "Best Parameters: {'max_depth': 30, 'n_estimators': 200}\n",
      "Accuracy: 0.3752066115702479\n",
      "Precision: 0.27683026856939896\n",
      "Recall: 0.3752066115702479\n",
      "F1 Score: 0.30644572334703596\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from pymongo import MongoClient\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Connect to MongoDB and load data\n",
    "client = MongoClient('mongodb+srv://w1798587:Success%402024@cluster0.69rs1dl.mongodb.net/')\n",
    "db = client['IntellCollab']\n",
    "collection = db['User_Project']\n",
    "cursor = collection.find()\n",
    "df = pd.DataFrame(cursor)\n",
    "df.fillna('', inplace=True)\n",
    "\n",
    "# Preprocess the data\n",
    "stop_words = set(stopwords.words('english'))\n",
    "porter = PorterStemmer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [token for token in tokens if token not in string.punctuation]\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    tokens = [porter.stem(token) for token in tokens]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df['Skills'] = df['Skills'].apply(preprocess_text)\n",
    "\n",
    "# Feature Engineering\n",
    "X = df[['Skills']]\n",
    "X['Skills'] = X['Skills'].str.split(',').apply(lambda x: ' '.join(x))  # Convert skills to separate features\n",
    "y = df['Industry_Project_Name']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# TF-IDF Vectorization (Content-Based Filtering)\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train['Skills'])\n",
    "\n",
    "# Model Selection and Hyperparameter Tuning\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "param_grid = {'n_estimators': [100, 200, 300], 'max_depth': [10, 20, 30]}\n",
    "grid_search = GridSearchCV(rf_classifier, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train_tfidf, y_train)\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "# Cross-Validation\n",
    "cv_scores = cross_val_score(best_rf_model, X_train_tfidf, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Evaluate on Test Set\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test['Skills'])\n",
    "y_pred = best_rf_model.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "print(\"Cross-Validation Mean Accuracy:\", cv_scores.mean())\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'cold war culture, propaganda'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/58/vdk28sms6qxgzmkckgchtb_h0000gn/T/ipykernel_7548/1394342885.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m# Standardize the input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0mX_train_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0mX_test_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;31m# Define the neural network model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             return_tuple = (\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    912\u001b[0m         \u001b[0;31m# non-optimized default implementation; override when a better\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m         \u001b[0;31m# method is possible for a given clustering algorithm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    835\u001b[0m             \u001b[0mFitted\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m         \"\"\"\n\u001b[1;32m    837\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 839\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1148\u001b[0m                 skip_parameter_validation=(\n\u001b[1;32m   1149\u001b[0m                     \u001b[0mprefer_skip_nested_validation\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m                 )\n\u001b[1;32m   1151\u001b[0m             ):\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0mFitted\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m         \"\"\"\n\u001b[1;32m    874\u001b[0m         \u001b[0mfirst_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"n_samples_seen_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 875\u001b[0;31m         X = self._validate_data(\n\u001b[0m\u001b[1;32m    876\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    601\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    912\u001b[0m                         )\n\u001b[1;32m    913\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m                 raise ValueError(\n\u001b[1;32m    918\u001b[0m                     \u001b[0;34m\"Complex data not supported\\n{}\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m                 ) from complex_warning\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0;31m# Use NumPy API to support order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;31m# container that is consistent with the input's namespace.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   2148\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2150\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2151\u001b[0m         if (\n\u001b[1;32m   2152\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2153\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'cold war culture, propaganda'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pymongo import MongoClient\n",
    "from flask import Flask, render_template, request\n",
    "\n",
    "# Initialize Flask\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient('mongodb+srv://w1798587:Success%402024@cluster0.69rs1dl.mongodb.net/')\n",
    "db = client['IntellCollab']\n",
    "collection = db['User_Project']\n",
    "# Load data from MongoDB into DataFrame\n",
    "def load_data():\n",
    "    cursor = collection.find()\n",
    "    data = list(cursor)\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "# Preprocess the data\n",
    "def preprocess_data(df):\n",
    "    # Remove duplicates\n",
    "    df.drop_duplicates(subset=['Industry_Project_Name'], keep='first', inplace=True)\n",
    "    # Remove rows with missing values\n",
    "    df.dropna(subset=['Project_Description', 'Skills', 'Industry_Company_Name'], inplace=True)\n",
    "    # Standardize text data\n",
    "    df['Project_Description'] = df['Project_Description'].str.lower().str.replace('[^\\w\\s]', '')\n",
    "    df['Skills'] = df['Skills'].str.lower().str.replace('[^\\w\\s]', '')\n",
    "    df['Industry_Company_Name'] = df['Industry_Company_Name'].str.lower().str.replace('[^\\w\\s]', '')\n",
    "    # Extract length of project descriptions as a feature\n",
    "    df['Description_Length'] = df['Project_Description'].apply(len)\n",
    "    return df\n",
    "# Train the logistic regression model\n",
    "def train_model(X_train_tfidf, y_train):\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "    return model\n",
    "\n",
    "# Load and preprocess data\n",
    "df = load_data()\n",
    "df = preprocess_data(df)\n",
    "\n",
    "# Split data into features (X) and target variable (y)\n",
    "X = df[['Skills']]\n",
    "y = df['Industry_Project_Name']\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Content-Based Filtering\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train['Skills'])\n",
    "from altair import SequentialMultiHue\n",
    "from networkx import dense_gnm_random_graph\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardize the input data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the neural network model\n",
    "model = SequentialMultiHue()\n",
    "model.add(dense_gnm_random_graph(100, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model on your data\n",
    "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=64, validation_data=(X_test_scaled, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Simulate predictions for demonstration purpose\n",
    "y_pred = model.predict(X_train_tfidf)\n",
    "\n",
    "# Compute evaluation metrics\n",
    "precision = precision_score(y_train, y_pred, average='micro')\n",
    "recall = recall_score(y_train, y_pred, average='micro')\n",
    "f1 = f1_score(y_train, y_pred, average='micro')\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Plot evaluation metrics\n",
    "metrics = ['Precision', 'Recall', 'F1 Score', 'Accuracy']\n",
    "scores = [precision, recall, f1, accuracy]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(metrics, scores, color=['blue', 'green', 'orange', 'red'])\n",
    "plt.xlabel('Metrics')\n",
    "plt.ylabel('Scores')\n",
    "plt.title('Evaluation Metrics')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['Skills'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 26\u001b[0m\n\u001b[1;32m     18\u001b[0m df\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Preprocess the data\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Add your preprocessing steps here\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \n\u001b[1;32m     23\u001b[0m \n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Split data into features (X) and target variable (y)\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m#X = df[['Project_Description', 'Skills']]\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSkills\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     27\u001b[0m y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIndustry_Project_Name\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Split data into training and testing sets\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/frame.py:4096\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4094\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4095\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4096\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4098\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexes/base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[1;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[0;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['Skills'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient('mongodb+srv://w1798587:Success%402024@cluster0.69rs1dl.mongodb.net/')\n",
    "db = client['IntellCollab']\n",
    "collection = db['User_Project']\n",
    "\n",
    "# Load data from MongoDB into DataFrame\n",
    "cursor = collection.find()\n",
    "df = pd.DataFrame(cursor)\n",
    "\n",
    "# Handle missing values by filling NaNs with empty strings\n",
    "df.fillna('', inplace=True)\n",
    "\n",
    "# Preprocess the data\n",
    "# Add your preprocessing steps here\n",
    "\n",
    "\n",
    "# Split data into features (X) and target variable (y)\n",
    "#X = df[['Project_Description', 'Skills']]\n",
    "X = df[['Skills']]\n",
    "y = df['Industry_Project_Name']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n",
    "\n",
    "# Content-Based Filtering\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "#X_train_tfidf = tfidf_vectorizer.fit_transform(X_train['Project_Description'] + ' ' + X_train['Skills'])\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train['Skills'])\n",
    "\n",
    "# Train logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "#X_test_tfidf = tfidf_vectorizer.transform(X_test['Project_Description'] + ' ' + X_test['Skills'])\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test['Skills'])\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate accuracy, precision, and F1 score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"F1 Score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2580246913580247\n",
      "Precision: 0.13623674801070473\n",
      "F1 Score: 0.1692450317749446\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' import pandas as pd\\nfrom sklearn.feature_extraction.text import TfidfVectorizer\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import accuracy_score, precision_score, f1_score\\nfrom pymongo import MongoClient\\nimport numpy as np\\n\\n# Connect to MongoDB\\nclient = MongoClient(\\'mongodb+srv://w1798587:Success%402024@cluster0.69rs1dl.mongodb.net/\\')\\ndb = client[\\'MyDatabase\\']\\ncollection = db[\\'Faculty_Project\\']\\n\\n# Load data from MongoDB into DataFrame\\ncursor = collection.find()\\ndf = pd.DataFrame(cursor)\\n\\n# Handle missing values by filling NaNs with empty strings\\ndf.fillna(\\'\\', inplace=True)\\n\\n# Preprocess the data\\n# Add your preprocessing steps here\\n\\n# Split data into features (X) and target variable (y)\\nX = df[[\\'Project_Description\\', \\'Skills\\']]\\ny = df[\\'Industry_Project_Name\\']\\n\\n# Split data into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\\n# Content-Based Filtering\\ntfidf_vectorizer = TfidfVectorizer(stop_words=\\'english\\')\\nX_train_tfidf = tfidf_vectorizer.fit_transform(X_train[\\'Project_Description\\'] + \\' \\' + X_train[\\'Skills\\'])\\n\\n# Train logistic regression model\\nmodel = LogisticRegression()\\nmodel.fit(X_train_tfidf, y_train)\\n\\n# Predict on test data\\nX_test_tfidf = tfidf_vectorizer.transform(X_test[\\'Project_Description\\'] + \\' \\' + X_test[\\'Skills\\'])\\ny_pred = model.predict(X_test_tfidf)\\n\\n# Calculate accuracy, precision, and F1 score\\naccuracy = accuracy_score(y_test, y_pred)\\nprecision = precision_score(y_test, y_pred, average=\\'micro\\')\\nf1 = f1_score(y_test, y_pred, average=\\'micro\\')\\n\\nprint(\"Accuracy:\", accuracy)\\nprint(\"Precision:\", precision)\\nprint(\"F1 Score:\", f1)\\n '"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient('mongodb://localhost:27017')\n",
    "db = client['IntellCollab']\n",
    "collection = db['Project']\n",
    "\n",
    "# Load data from MongoDB into DataFrame\n",
    "cursor = collection.find()\n",
    "df = pd.DataFrame(cursor)\n",
    "\n",
    "# Handle missing values by filling NaNs with empty strings\n",
    "df.fillna('', inplace=True)\n",
    "\n",
    "# Preprocess the data\n",
    "# Add your preprocessing steps here\n",
    "\n",
    "\n",
    "# Split data into features (X) and target variable (y)\n",
    "#X = df[['Project_Description', 'Skills']]\n",
    "X = df[['Skills']]\n",
    "y = df['Industry_Project_Name']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Content-Based Filtering\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "#X_train_tfidf = tfidf_vectorizer.fit_transform(X_train['Project_Description'] + ' ' + X_train['Skills'])\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train['Skills'])\n",
    "\n",
    "# Train logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "#X_test_tfidf = tfidf_vectorizer.transform(X_test['Project_Description'] + ' ' + X_test['Skills'])\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test['Skills'])\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate accuracy, precision, and F1 score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "''' import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
    "from pymongo import MongoClient\n",
    "import numpy as np\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient('mongodb+srv://w1798587:Success%402024@cluster0.69rs1dl.mongodb.net/')\n",
    "db = client['MyDatabase']\n",
    "collection = db['Faculty_Project']\n",
    "\n",
    "# Load data from MongoDB into DataFrame\n",
    "cursor = collection.find()\n",
    "df = pd.DataFrame(cursor)\n",
    "\n",
    "# Handle missing values by filling NaNs with empty strings\n",
    "df.fillna('', inplace=True)\n",
    "\n",
    "# Preprocess the data\n",
    "# Add your preprocessing steps here\n",
    "\n",
    "# Split data into features (X) and target variable (y)\n",
    "X = df[['Project_Description', 'Skills']]\n",
    "y = df['Industry_Project_Name']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Content-Based Filtering\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train['Project_Description'] + ' ' + X_train['Skills'])\n",
    "\n",
    "# Train logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test['Project_Description'] + ' ' + X_test['Skills'])\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate accuracy, precision, and F1 score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='micro')\n",
    "f1 = f1_score(y_test, y_pred, average='micro')\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"F1 Score:\", f1)\n",
    " '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/58/vdk28sms6qxgzmkckgchtb_h0000gn/T/ipykernel_3530/3087196538.py:23: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.fillna('', inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Mean Accuracy: 0.40919015108738427\n",
      "Best Parameters: {'max_depth': 30, 'n_estimators': 300}\n",
      "Accuracy: 0.3685950413223141\n",
      "Precision: 0.3685950413223141\n",
      "Recall: 0.3685950413223141\n",
      "F1 Score: 0.29962103323673567\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from pymongo import MongoClient\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "\n",
    "# Download NLTK resources\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "\n",
    "# Connect to MongoDB and load data\n",
    "client = MongoClient('mongodb://localhost:27017')\n",
    "db = client['IntellCollab']\n",
    "collection = db['User_Project']\n",
    "cursor = collection.find()\n",
    "df = pd.DataFrame(cursor)\n",
    "df.fillna('', inplace=True)\n",
    "\n",
    "# Preprocess the data\n",
    "stop_words = set(stopwords.words('english'))\n",
    "porter = PorterStemmer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [token for token in tokens if token not in string.punctuation]\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    tokens = [porter.stem(token) for token in tokens]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df['Skills'] = df['Skills'].apply(preprocess_text)\n",
    "\n",
    "# Feature Engineering\n",
    "X = df['Skills']\n",
    "y = df['Industry_Project_Name']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# TF-IDF Vectorization (Content-Based Filtering)\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Model Selection and Hyperparameter Tuning\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "param_grid = {'n_estimators': [100, 200, 300], 'max_depth': [10, 20, 30]}\n",
    "grid_search = GridSearchCV(rf_classifier, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train_tfidf, y_train)\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "# Cross-Validation\n",
    "cv_scores = cross_val_score(best_rf_model, X_train_tfidf, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Evaluate on Test Set\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "y_pred = best_rf_model.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "print(\"Cross-Validation Mean Accuracy:\", cv_scores.mean())\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'IntellCollab_Dataseet.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 26\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m precision, recall, f1\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Get the path to the dataset within the virtual environment\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Load data\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mIntellCollab_Dataseet.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Content-Based Filtering\u001b[39;00m\n\u001b[1;32m     29\u001b[0m tfidf_vectorizer \u001b[38;5;241m=\u001b[39m TfidfVectorizer(stop_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'IntellCollab_Dataseet.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "''' df = pd.read_csv('spam_ham_dataset.csv')\n",
    "#Checking dataset info\n",
    "df.info()\n",
    "df.head(5171) '''\n",
    "\n",
    "# Function to recommend projects based on user skills\n",
    "def recommend_projects(user_skills):\n",
    "    user_vector = tfidf_vectorizer.transform([user_skills])\n",
    "    similarities = cosine_similarity(user_vector, tfidf_matrix)\n",
    "    sorted_similarities = sorted(enumerate(similarities.squeeze()), key=lambda x: x[1], reverse=True)\n",
    "    recommended_project_ids = [i[0] for i in sorted_similarities[:10]]  # Top 10 recommendations\n",
    "    return recommended_project_ids\n",
    "\n",
    "# Function to evaluate recommendations\n",
    "def evaluate_recommendations(recommended_project_ids, relevant_project_ids):\n",
    "    precision = precision_score(relevant_project_ids, recommended_project_ids)\n",
    "    recall = recall_score(relevant_project_ids, recommended_project_ids)\n",
    "    f1 = f1_score(relevant_project_ids, recommended_project_ids)\n",
    "    return precision, recall, f1\n",
    "\n",
    "# Get the path to the dataset within the virtual environment\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('IntellCollab_Dataseet.csv')\n",
    "\n",
    "# Content-Based Filtering\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df['Skills'])\n",
    "\n",
    "# Split data into training and testing sets\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Evaluate recommendations for each user in the test set\n",
    "evaluation_results = []\n",
    "for _, row in test_data.iterrows():\n",
    "    recommended_project_ids = recommend_projects(row['Skills'])\n",
    "    relevant_project_ids = get_user_relevant_projects(row['User_ID'])  # Implement this function to retrieve relevant projects\n",
    "    precision, recall, f1 = evaluate_recommendations(recommended_project_ids, relevant_project_ids)\n",
    "    evaluation_results.append({'User_ID': row['User_ID'], 'Precision': precision, 'Recall': recall, 'F1-Score': f1})\n",
    "\n",
    "# Create DataFrame from evaluation results\n",
    "evaluation_df = pd.DataFrame(evaluation_results)\n",
    "\n",
    "# Display evaluation results\n",
    "print(\"Evaluation Results:\")\n",
    "print(evaluation_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 3 fields in line 10, saw 4\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, precision_score, f1_score\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Load data from CSV\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m df_csv \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mIntellCollab_Dataset.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Content-Based Filtering for CSV data\u001b[39;00m\n\u001b[1;32m     11\u001b[0m tfidf_vectorizer_csv \u001b[38;5;241m=\u001b[39m TfidfVectorizer(stop_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1919\u001b[0m     (\n\u001b[1;32m   1920\u001b[0m         index,\n\u001b[1;32m   1921\u001b[0m         columns,\n\u001b[1;32m   1922\u001b[0m         col_dict,\n\u001b[0;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1925\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32mparsers.pyx:838\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:905\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:2061\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 3 fields in line 10, saw 4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
    "\n",
    "# Load data from CSV\n",
    "df_csv = pd.read_csv('IntellCollab_Dataset.csv')\n",
    "\n",
    "# Content-Based Filtering for CSV data\n",
    "tfidf_vectorizer_csv = TfidfVectorizer(stop_words='english')\n",
    "X_tfidf_csv = tfidf_vectorizer_csv.fit_transform(df_csv['Skills'])\n",
    "\n",
    "# Split data into features (X) and target variable (y) for CSV data\n",
    "X_csv = df_csv[['Skills']]\n",
    "y_csv = df_csv['Industry_Project_Name']\n",
    "\n",
    "# Split data into training and testing sets for CSV data\n",
    "X_train_csv, X_test_csv, y_train_csv, y_test_csv = train_test_split(X_csv, y_csv, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train logistic regression model for CSV data\n",
    "model_csv = LogisticRegression()\n",
    "model_csv.fit(X_tfidf_csv, y_train_csv)  # Use X_tfidf_csv here\n",
    "\n",
    "# Predict on test data for CSV data\n",
    "X_test_tfidf_csv = tfidf_vectorizer_csv.transform(X_test_csv['Skills'])\n",
    "y_pred_csv = model_csv.predict(X_test_tfidf_csv)\n",
    "\n",
    "# Calculate accuracy, precision, and F1 score for CSV approach\n",
    "accuracy_csv = accuracy_score(y_test_csv, y_pred_csv)\n",
    "precision_csv = precision_score(y_test_csv, y_pred_csv, average='weighted', zero_division=0)\n",
    "f1_csv = f1_score(y_test_csv, y_pred_csv, average='weighted')\n",
    "\n",
    "print(\"\\nEvaluation Results for CSV approach:\")\n",
    "print(\"Accuracy:\", accuracy_csv)\n",
    "print(\"Precision:\", precision_csv)\n",
    "print(\"F1 Score:\", f1_csv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pymongo import MongoClient\n",
    "from flask import Flask, render_template, request\n",
    "\n",
    "# Initialize Flask\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient('mongodb+srv://w1798587:Success%402024@cluster0.69rs1dl.mongodb.net/')\n",
    "db = client['IntellCollab']\n",
    "collection = db['User_Project']\n",
    "\n",
    "\n",
    "# Load data from MongoDB into DataFrame\n",
    "def load_data():\n",
    "    cursor = collection.find()\n",
    "    data = list(cursor)\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "# Preprocess the data\n",
    "def preprocess_data(df):\n",
    "    # Remove duplicates\n",
    "    df.drop_duplicates(subset=['Industry_Project_Name'], keep='first', inplace=True)\n",
    "    # Remove rows with missing values\n",
    "    df.dropna(subset=['Project_Description', 'Skills', 'Industry_Company_Name'], inplace=True)\n",
    "    # Standardize text data\n",
    "    df['Project_Description'] = df['Project_Description'].str.lower().str.replace('[^\\w\\s]', '')\n",
    "    df['Skills'] = df['Skills'].str.lower().str.replace('[^\\w\\s]', '')\n",
    "    df['Industry_Company_Name'] = df['Industry_Company_Name'].str.lower().str.replace('[^\\w\\s]', '')\n",
    "    # Extract length of project descriptions as a feature\n",
    "    df['Description_Length'] = df['Project_Description'].apply(len)\n",
    "    return df\n",
    "\n",
    "# Train the logistic regression model\n",
    "def train_model(X_train_tfidf, y_train):\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "    return model\n",
    "\n",
    "\n",
    "# Load and preprocess data\n",
    "df = load_data()\n",
    "df = preprocess_data(df)\n",
    "\n",
    "\n",
    "# Split data into features (X) and target variable (y)\n",
    "X = df[['Project_Description', 'Skills']]\n",
    "y = df['Industry_Project_Name']\n",
    "\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Content-Based Filtering\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train['Project_Description'] + ' ' + X_train['Skills'])\n",
    "\n",
    "# Train logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "from altair import SequentialMultiHue\n",
    "from networkx import dense_gnm_random_graph\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardize the input data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the neural network model\n",
    "model = SequentialMultiHue()\n",
    "model.add(dense_gnm_random_graph(100, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model on your data\n",
    "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=64, validation_data=(X_test_scaled, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Simulate predictions for demonstration purpose\n",
    "y_pred = model.predict(X_train_tfidf)\n",
    "\n",
    "# Compute evaluation metrics\n",
    "precision = precision_score(y_train, y_pred, average='micro')\n",
    "recall = recall_score(y_train, y_pred, average='micro')\n",
    "f1 = f1_score(y_train, y_pred, average='micro')\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "# Print evaluation metrics\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Plot evaluation metrics\n",
    "metrics = ['Precision', 'Recall', 'F1 Score', 'Accuracy']\n",
    "scores = [precision, recall, f1, accuracy]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(metrics, scores, color=['blue', 'green', 'orange', 'red'])\n",
    "plt.xlabel('Metrics')\n",
    "plt.ylabel('Scores')\n",
    "plt.title('Evaluation Metrics')\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
